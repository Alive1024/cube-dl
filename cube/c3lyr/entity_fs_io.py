import json
import os
import os.path as osp
import re
import shutil
from collections import OrderedDict
from datetime import datetime

from pytorch_lightning.utilities.rank_zero import rank_zero_only


class EntityFSIO:
    """
    A collection of functions for entities to interact with the file system.
    """

    @staticmethod
    @rank_zero_only
    def make_dir(target_dir, created_type: str, print_message=True):
        if not osp.exists(target_dir):
            os.mkdir(target_dir)
        if print_message:
            print(f'{created_type}: "{osp.split(target_dir)[1]}" created, storage path: {target_dir}')

    # >>>>>>>>>>>>>> Dealing with pytorch_lightning.loggers.CSVLogger's metrics.csv >>>>>>>>>>>>>>
    @staticmethod
    @rank_zero_only
    def process_metrics_csv(run_dir):
        """
        Since pytorch_lightning.loggers.CSVLogger will override previous "metrics.csv",
        special process is needed when resuming fit to avoid "metrics.csv" being overridden.
        """
        metrics_csv_path = osp.join(run_dir, "metrics.csv")
        if osp.exists(metrics_csv_path):
            # Rename the original "metrics.csv" to "metrics_<max_cnt>.csv",
            # to reserve the filename "metrics.csv" when resuming fit.
            indices = []
            for filename in os.listdir(run_dir):
                match = re.match(r"metrics_(\d+).csv", filename)
                if match:
                    indices.append(int(match.group(1)))
            max_cnt = 1 if len(indices) == 0 else max(indices) + 1
            shutil.move(metrics_csv_path, metrics_csv_path[:-4] + f"_{max_cnt}.csv")

    @staticmethod
    @rank_zero_only
    def merge_metrics_csv(run_dir):
        """
        Merge multiple metrics_csv (if any) into "merged_metrics.csv".
        The correct order is "metrics_1.csv" -> "metrics_2.csv" -> ... -> "metrics.csv".
        """
        metrics_csv_files = [
            filename
            for filename in os.listdir(run_dir)
            if filename.startswith("metrics_") and filename.endswith(".csv")
        ]
        metrics_csv_files.sort(key=lambda x: int(osp.splitext(x)[0].split("_")[1]))
        # Append the latest one to the last.
        if osp.exists(osp.join(run_dir, "metrics.csv")):
            metrics_csv_files.append("metrics.csv")
        if len(metrics_csv_files) > 1:
            with open(osp.join(run_dir, "merged_metrics.csv"), "w") as merged_metrics_csv:
                for csv_idx, csv_filename in enumerate(metrics_csv_files):
                    with open(osp.join(run_dir, csv_filename)) as metrics_csv:
                        if csv_idx != 0:
                            next(metrics_csv)  # skip the csv header to avoid repetition
                        merged_metrics_csv.write(metrics_csv.read())

    # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Methods for Saving Files. >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    @staticmethod
    @rank_zero_only
    def save_hparams(run_dir, hparams: OrderedDict, **kwargs):
        """
        Save hparams to json files. "hparams.json" always indicates the latest, similar to "metrics.csv".
        """
        hparams_json_path = osp.join(run_dir, "hparams.json")
        if osp.exists(hparams_json_path):
            indices = []
            for filename in os.listdir(run_dir):
                match = re.match(r"hparams_(\d+).json", filename)
                if match:
                    indices.append(int(match.group(1)))

            max_cnt = 1 if len(indices) == 0 else max(indices) + 1
            shutil.move(
                hparams_json_path,
                osp.splitext(hparams_json_path)[0] + f"_{max_cnt}.json",
            )

        hparams.update(kwargs)
        with open(hparams_json_path, "w", encoding="utf-8") as f:
            json.dump(hparams, f, indent=2)

    @staticmethod
    @rank_zero_only
    def remove_empty_hparams_yaml(run_dir):
        # Remove the empty "hparams.yaml" generated by PyTorch-Lightning
        hparams_yaml_path = osp.join(run_dir, "hparams.yaml")
        needs_removed = False
        if osp.exists(hparams_yaml_path):
            with open(hparams_yaml_path) as f:
                if f.read().strip() == "{}":
                    needs_removed = True
        if needs_removed:
            os.remove(hparams_yaml_path)

    @staticmethod
    @rank_zero_only
    def save_model_structure(run_dir, model):
        with open(osp.join(run_dir, "model_structure.txt"), "w") as f:
            f.write(repr(model))

    @staticmethod
    @rank_zero_only
    def mkdir_for_predictions(run_dir, prediction_dir_prefix="predictions") -> str:
        prediction_dir = osp.join(
            run_dir,
            f"{prediction_dir_prefix}_" f"{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}",
        )
        os.mkdir(prediction_dir)
        return prediction_dir

    # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
